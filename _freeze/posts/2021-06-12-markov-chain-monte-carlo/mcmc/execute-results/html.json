{
  "hash": "cc08ab74b6404fa21294753c8a1e017d",
  "result": {
    "markdown": "---\ntitle: \"Markov Chain Monte Carlo\"\ndescription: |\n  Introduction to MCMC\nauthor: \"Don Don\"\ndate: \"2021-01-06\"\ncategories: [R, statistics]\nimage: \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Metropolis_hastings_algorithm.png/450px-Metropolis_hastings_algorithm.png\"\n---\n\n# Markov Chain Monte Carlo(MCMC)\n\n켤레 사전 분포처럼 분포함수 간에 관계가 있거나 함수가 간단한 형태의 경우\n적분을 쉽게 할 수 있다. 하지만 복잡한 함수 형태이거나 high dimension인\n경우 Monte carlo integration이나 numerical method를 이용한 적분 방법을\n적용하기 힘들다. 이 때 사용하는 방법이 Markov chain Monte Carlo\n방법이다.\n\nMonte Carlo integration의 경우 independence sample을 뽑는데 high\ndimension인 경우 independence sample을 뽑는 것이 어렵다. 따라서\ndependence sample을 뽑아서 이 문제를 해결해보자는 것이 Markov Chain\nMonte Carlo(MCMC)의 아이디어이다. 앞에 Markov Chain이 붙은 것은\ndependence sample을 Markov Chain 구조에서 뽑기 때문이다. 이상적인 Markov\nChain의 경우 특정 정칙 조건을 만족해야한다.\n\n## regularity conditions\n\n-   irreducibility\n-   positive recurrence\n-   aperiodicity\n\n# Metopolis-Hasting algorithm\n\nMarkov Chain을 따르는 $X$를 발생시키기 위해서는 regularity conditions을\n만족해야 한다. **일반적으로 target distribution과 같은 support set을\n갖는 proposal distribution의 경우 regularity conditions를 만족한다.**\nproposal distribution이 regularity condition을 만족하는 경우\nMetropolis-Hastings chain의 stationary distribution은 taget\ndistribution이 된다.\n\n1.  target distribution과 support set이 같은 임의의 proposal\n    distribution $g(\\cdot|X_t)$를 선정한다.\\\n2.  $g(\\cdot|X_t)$에서 초기값 $X_0$를 생성한다.\n3.  chain이 정상 분포로 수렴할 때까지 다음의 과정을 반복한다.\n\n-   $g(\\cdot|X_t)$로부터 $Y$를 발생시킨다.\n-   $U(0,1)$에서 random number $U$를 발생시킨다.\n-   If $U\\le r(X_t, Y) = \\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}$ $Y$를\n    채택, $X_{t+1}=Y$ otherwise $X_{t+1}=X_t$\n-   Increment t\n\n## Example\n\nMetropolis-Hasting algorithm을 이용해서 Rayleigh 분포에서 표본을\n추출하기 해보자.\n\n$f(x) = \\frac{x}{\\sigma^2}e^\\frac{-x^2}{2\\sigma^2}$, $x\\ge0$, $\\sigma>0$\n\n1.  target distribution과 support set이 같은 임의의 proposal\n    distribution로 $\\mathcal{X}^2(X)$를 선정한다.\\\n2.  $\\mathcal{X}^2(1)$에서 초기값 $X_0$를 생성하고 x[1]에 저장한다.\\\n3.  $i=2,...,N$까지 반복한다.\n\n-   $\\mathcal{X}^2(df = X_t)=\\mathcal{X}^2(df = X[i-1])$로부터 $Y$를\n    발생시킨다.\n-   $U(0,1)$에서 random number $U$를 발생시킨다.\n-   $X_t$=x[i-1], If $U\\le \\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}$ $Y$를\n    채택, $X_{t+1}=Y$ otherwise $X_{t+1}=X_t$ $X_t+1$을 x[i]에 저장한다.\n-   Increment t\n\n$Y$가 accept 될 확률은 다음과 같다.\n$\\alpha (X_t, Y) = min(1, \\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)})$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrayleigh <- function(x, sigma){\n        return ((x/sigma^2)*exp(-x^2/(2*sigma^2))) # Rayleigh distribution를 함수로 정의\n}\n\nm <- 10000\nsigma <- 4\nx <- numeric(m)\nx[1] <- rchisq(1, df = 1) # initial value \nk <- 0 \nu <- runif(m) # generate u from U(0,1)\n\nfor (i in 2:m) {\n        xt <- x[i-1]\n        y <- rchisq(1, df = xt)\n        num <- rayleigh(y, sigma)*dchisq(xt, df = y) # posterior theta t\n        den <- rayleigh(xt, sigma)*dchisq(y, df = xt) # posterior theta t-1\n        \n        if (u[i] <= num/den) {\n                x[i] <- y # accept \n        }else {\n                x[i] <- xt # reject \n                k <- k+1\n        }\n}\nk # reject된 갯수 \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4000\n```\n:::\n:::\n\n\n실제 Rayleigh 분포와 같은지를 비교하기 위해 QQplot을 그리면 다음과 같다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb <- 2001\ny <- x[b:m]\na <- ppoints(100)\nQR <- sigma*sqrt(-2*log(1-a))\nQ <- quantile(y, a)\n\nqqplot(QR, Q, main = '', cex = 0.5, xlab = 'Rayleigh Quantiles', ylab = 'Sample Quantiles')\nabline(0,1)\n```\n\n::: {.cell-output-display}\n![](mcmc_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nproposal distribution을 gamma distribution으로 변경할 경우 다음과 같다.\n\n# Metropolis Sampler\n\nMatropolis Hastings sampler는 Metropolis sampler의 일반화이다.\nMetropolis sampler는 Metropolis algorithm에서 proposal distribution이\nsymmetric일 때를 의미한다.\n\nproposal distribution이 symmetric이므로\n\n$g(X|Y) = g(Y|X)$\n\n를 만족한다.\n\n따라서 기존의 Metropolis Hastings sampler 식은 조건부 분포 $g$가\n약분되므로 식이 간소화된다.\n$r(X_t, Y) = \\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)} = \\frac{f(Y)}{f(X_t)}$\n\n# Random Walk Metropolis\n\nRandom Walk Metropolis sampler는 Metropolis Sampler의 special case이다.\nproposal distribution은 symmetric이며, $g(Y|X_t) = g(X_t - Y)$로\n정의한다.\n\n1.  random increment $Z$를 $g(\\cdot)$로 부터 발생시킨다.\n\n2.  $Y=X_t+Z$ 로 정의한다.\n\n3.  $r(X_t, Y) = \\frac{f(Y)}{f(X_t)}$를 계산한다.\n\n4.  target distribution과 support set이 같은 임의의 proposal\n    distribution $g(\\cdot|X_t)$를 선정한다. proposal distribution은\n    symmetric이며, $g(Y|X_t) = g(X_t - Y)$로 정의한다.\n\n5.  random increment $Z$를 $g(\\cdot)$로 부터 발생시키고, $Y=X_t+Z$ 로\n    정의한다.\n\n6.  chain이 정상 분포로 수렴할 때까지 다음의 과정을 반복한다.\n\n-   $r(X_t, Y) = \\frac{f(Y)}{f(X_t)}$를 계산한다.\n-   $U(0,1)$에서 random number $U$를 발생시킨다.\n-   If $U\\le r(X_t, Y) = \\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}$ $Y$를\n    채택, $X_{t+1}=Y$ otherwise $X_{t+1}=X_t$\n-   Increment t\n\n# independence sampler\n\nindependence sampler는 Metropolis Hastings Sampler의 special case이다.\nindependence sampler에서 proposal distribution은 다음과 같이 정의된다.\n\n$g(Y|X_t) = g(Y)$\n\n즉, independence sampler는 chain의 이전 값에 의존하지 않는다.\n\nindependence sampler는 proposal density가 target density에 가깝게\nmatch될 경우에 잘 동작한다. 하지만 이러한 경우는 거의 없으며,\nindependence sampler는 잘 동작하지 않는 경우가 많다. 따라서 단독으로\n쓰이는 경우는 없으며, 보통 hybrid MCMC method에서 사용한다.\n\n# Gibbs sampler\n\nGibbs sampler도 Metropolis Hastings Sampler의 special case이다. target\ndistribution이 multivariate distribution일 때 주로 적용한다. Gibbs\nsampler는 일변량 조건부 분포를 계산할 수 있고, 쉽게 simulation이 가능한\n경우에 사용할 수 있다.\n\n$X_{(-j)} = (X_1, ... , X_{j-1}, X_{j+1}, ... , X_d)$\n\n$f(x_1, x_2, ..., x_k)$ : joint pdf를 계산하기 어려움\n$f(x_1) = \\int f(x_1, x_2, ..., x_k)\\, dx_2...dx_d$ : marginal pdf를\n계산하기 어려움 $f(x_1|x_2,...,x_d)$ : conditional pdf는 구하기 쉬움\n\n간단하게 multivariate distribution일 때를 예로 들면\n\n$f(x, y)$ : joint pdf를 계산하기 어려움 $f(x) = \\int f(x,y)\\, dy$ :\nmarginal pdf를 계산하기 어려움 $f(y) = \\int f(x,y)\\, dx$ $f(x|y)$,\n$f(y|x)$ : conditional pdf는 구하기 쉬움\n\nGibbs sampler를 직관적으로 설명하면\n\n1.  $y$가 주어졌을 때 $f(x|y)$로 부터 구한 $x$값을 $f(y|x)$의 given\n    $x$값으로 집어넣는다.\n2.  $f(y|x)$에서 나온 $y$값을 $f(x|y)$의 given $y$ 값으로 집어넣는다.\n3.  이러한 과정을 계속 반복해서 $(X_1, Y_1, ....)$를 구한다.\n4.  $(X_1, Y_1, ....|X_i, Y_i......)$의 일정 부분을 burn out하고\n    $(X_i, Y_i......)$만 남긴다.\n5.  $(X_i, Y_i......)$는 $f(x,y)$에서 뽑은 sample이 된다.\n\n즉, Gibbs sampler의 핵심은 conditinal pdf로부터 joint pdf or marginal\npdf를 쉽게 계산할 수 있다는 것이다. 핵심이다.\n\n## Gibbs sampler algorithm\n\n$X_{(-j)} = (X_1, ... , X_{j-1}, X_{j+1}, ... , X_d)$\n\n1.  $t=0$ 시점에서의 초기값 $X(0)$를 생성한다.\n2.  $t=1, 2, ...$ 에 대해 다음을 반복한다.\n\n-   $x_1=X_1(t-1)$을 구한다.\n-   각 $j = 1, 2,...,d$에 대해\n\n(a) $f(X_j|x_{(-j)})$로 부터 $X_j^*(t)$를 발생시킨다.\n(b) $x_j=X_j^*(t)$를 update한다.\n\n-   $X(t)=(X_1^*(t), ... , X_d^*(t)$를 구한다.\n-   Increment t\n\n### Example (beta-binomial distribution)\n\n$f(x,y) = {n \\choose x}y^{x+a-1}(1-y)^{n-x+b-1}$, $x=0,1,....,n$,\n$0 \\le y \\le 1$ $X|y \\sim Bin(n, y)$,\n$Y|x \\sim Beta(x+\\alpha, n-x+\\beta)$\n\nGibbs sampling의 목적은 conditional pdf로 모르는 형태의 joint pdf와\nmarginal pdf를 구하는 것이다. 따라서 $f(x,y)$는 실제로는 beta-binomial\n분포로 구할 수 있지만 gibbs sampling을 위해서 $f(x,y)$를 모르고\n$f(x|y)$와 $f(y|x)$는 안다고 가정한다.\n\n### Algorithm\n\n1.  $Bin(n, p = Y(t-1))$로부터 $X^*(t)$를 발생시킨다.\n2.  $x(t) = X^*(t)$를 update한다.\n3.  $Beta(x(t)+\\alpha, n-x(t)+\\beta)$로부터 $Y^*(t)$를 발생시킨다.\n4.  Set $(X(t), Y(t)) = (X^*(t), Y^*(t))$.\n\n추가적으로 $(X^*(t), Y^*(t))$에 대해서 일정량을 burn in 하는데 이는\n초기값의 영향을 없애기 위해서이다. burn in의 비율은 임의로 설정한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 500               \nburn <- 100            \nn <- 16\nalpha <- 2\nbeta <- 4\nx <- rep(0, N)\ny <- rep(0, N)\n\n\nx[1] <- rbinom(1, prob = 0.5, size = n)\ny[1] <- rbeta(1, x[1]+alpha, n-x[1]+beta)\n\nfor (i in 2:N) {\n        x[i] <- rbinom(1, prob = y[i-1], size = n)\n        y[i] <- rbeta(1, x[i]+alpha, n-x[i]+beta)\n}\n\nburn_x <- x[(burn+1):N]\n```\n:::\n\n\n### Example (Bivariate distribution)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 5000               \nburn <- 1000            \nX <- matrix(0, N, 2)    \n\nrho <- -.75             \nmu1 <- 0\nmu2 <- 2\nsigma1 <- 1\nsigma2 <- .5\ns1 <- sqrt(1-rho^2)*sigma1\ns2 <- sqrt(1-rho^2)*sigma2\n\n\nX[1, ] <- c(mu1, mu2) # 초기값\n\nfor (i in 2:N) {\n        x2 <- X[i-1, 2] # x2가 주어짐\n        m1 <- mu1 + rho * (x2 - mu2) * sigma1/sigma2 # x2가 주어졌을 때 x1 조건부 분포의 평균 \n        X[i, 1] <- rnorm(1, m1, s1) # 조건부 분포로 생성된 x1 업데이트 \n        x1 <- X[i, 1]\n        m2 <- mu2 + rho * (x1 - mu1) * sigma2/sigma1 # x1이 주어졌을 때 x2 조건부 분포의 평균\n        X[i, 2] <- rnorm(1, m2, s2) # 조건부 분포로 생성된 x1 업데이트\n}\n\nb <- burn + 1 # 임의로 부여한 initial value의 효과를 없앰. \nx <- X[b:N, ] # 1000개 버림\n\ncolMeans(x) # 0, 2에 거의 근사 \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.02094119  2.00648931\n```\n:::\n\n```{.r .cell-code}\ncov(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           [,1]       [,2]\n[1,]  0.9582500 -0.3503596\n[2,] -0.3503596  0.2371582\n```\n:::\n\n```{.r .cell-code}\ncor(x) # rho = -0.75에 거의 근사 \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           [,1]       [,2]\n[1,]  1.0000000 -0.7349462\n[2,] -0.7349462  1.0000000\n```\n:::\n\n```{.r .cell-code}\nplot(x, main = '', cex = 0.5, xlab = bquote(X[1]), ylab = bquote(X[2]), ylim = range(x[, 2]))\n```\n\n::: {.cell-output-display}\n![](mcmc_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "mcmc_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}